---
title: "Détection de maladies cardiovasculaire"
subtitle: "Comparaison de classifieurs via les courbes ROC"
author: "___"
date: "`r Sys.Date()`"
format:
  html:
    code-fold: true
    code-tools: true
    toc: true
editor: visual
lang: fr
bibliography: biblio/references.bib
---

```{r setup, include=FALSE}
# This is needed to the SDD test suite, do not use in a "real" project
if (!"tools:tests" %in% search())
  source(here::here("tests/tools_tests.R"), attach(NULL, name = "tools:tests"))

# Configure SciViews::R environment
SciViews::R("ml", lang = "fr")
```

# Introduction et but

Les maladies cardiovasculaires touchent 7% de la population américaine [@anation2011]. Un diagnostic précoce est une étape clé dans le traitement de ces maladies. Dans ce contexte, nous cherchons à mettre au point un classifieur capable de détecter les personnes à risque sur base de données assez générales (morphométrie de base, pression artérielle, analyse de sang basique).

# Matériel et méthodes

Les données proviennent du jeu vérifié et remanié dans `cardio_propotions.qmd`. Voir ce dernier document pour les détails.

# Résultats

Les données sont nettoyées, et de nouvelles variables sont calculées dans `cardio_proportions.qmd`. Nous repartons ici du même jeu de données `cardio3`.

```{r import2, record='RODFS', object='cardio2'}
cardio2 <- read("___")
```

<!--% Divisez votre jeu de données en cardio3_train et cardio3_test (2/3 en apprentissage, stratifié en fonction de cardio) -->

```{r split, record='RODFS', object='cardio2_train'}
set.seed(8945611)
cardio2_split <- initial_split(___)
cardio2_train <- ___
cardio2_test <- ___
```

## Forêt aléatoire

Nous entraînons un classifieur forêt aléatoire et étudions ses performances sur base de courbes ROC.

<!--% Entraînez un classifieur par forêt aléatoire sur cardio_train afin de prédire la variable `cardio`. Limitez le nombre d'arbres à 200 (considérez que vous avez obtenu cette valeur sur base d'une optimisation étape par étape de votre classifieur). -->

```{r rf, record='ROP', object='cardio2_rf', arg='ntree,mtry'}
set.seed(15416549)
cardio2_rf <- ml_rforest(data = ___,  ___)
```

Les probabilités d'appartenance aux deux catégories relatives aux maladies cardiovasculaires sont calculées. Voici ci-dessous les résultats pour six cas du set de test :

<!--% Calculez les probabilités d'appartenance aux classes à partir de votre classifieur en utilisant le set de test -->

```{r rf_mem, record='ROMD5', object='cardio2_rf_mem'}
cardio2_rf_mem <- predict(___, ___, type = "___")
head(cardio2_rf_mem)
```

Voici la courbe ROC pour notre classifieur à forêt aléatoire.

<!--% Calculez et affichez la courbe ROC pour ce classifieur en utilisant les métriques tpr et fpr -->

```{r rf_roc, record='ROMD5', object='cardio2_rf_perf'}
# 1) Créer un objet prediction
cardio2_rf_predobj <- prediction(___,
  ___ == "présence")
# 2) Calculer les performances avec les deux métriques tpr et fpr
cardio2_rf_perf <- ___
# 3) Tracer le graphique ROC
___
abline(a = 0, b = 1, lty = 2)
```

L'aire sous la courbe est :

<!-- Calculez l'aire sous la courbe ROC. -->

```{r rf_auc, record='RNA', arg='class'}
___
```

## Machine à vecteurs supports

Nous réalisons un second classifieur à vecteurs supports en utilisant un noyau radial.

<!--% Entraînez un second classifieur à l'aide de la machine à vecteurs supports avec le même set d'apprentissage -->

<!--# La méthode SVM a beaucoup de paramètres à optimiser, mais dans le cadre de cet exercice, commencez par la version avec tous les paramètres par défaut, et donc, un noyau radial. S'il reste du temps quand vous avez tout fini, vous pouvez explorer d'autres valeurs des paramètres et comparer toujours avec courbe ROC les versions originale et optimisée (vous pouvez ajouter une troisième courbe sur le graphique final du document). -->

```{r svm, record='ROP', object='cardio2_svm', arg='probA,probB'}
set.seed(487063)
cardio2_svm <- ml_svm(data = ___, ___)
```

Voici les probabilités d'appartenance aux deux catégories pour les six premiers cas du set de test :

<!--% Calculez les probabilités d'appartenance aux classes à partir de votre classifieur via le set de test. -->

```{r svm_mem, record='ROMD5', object='cardio2_svm_mem'}
cardio2_svm_mem <- ___
head(cardio2_svm_mem)
```

La courbe ROC pour ce classifieur à vecteurs supports donne ceci :

<!--% Calculez et affichez la courbe ROC pour ce classifieur en utilisant les métriques tpr et fpr. -->

```{r svm_roc, record='ROMD5', object='cardio2_svm_perf'}
# 1) Créer un objet prediction
cardio2_svm_predobj <- ___(___,
  ___)
# 2) Calculer les performances avec les deux métriques tpr et fpr
cardio2_svm_perf <- ___
# 3) Tracer le graphique ROC
___
abline(a = 0, b = 1, lty = 2)
```

L'aire sous la courbe est :

<!-- Calculez l'aire sous la courbe ROC. -->

```{r svm_auc, record='RNA', arg='class'}
___
```

## Comparaison des deux classifieurs

Nous comparons le classifieur à forêt aléatoire et le classifieur machine à vecteurs supports sur base de leurs courbes ROC respectives ci-dessous.

<!--% Comparez les deux classifieurs en affichant leurs courbes ROC sur un même graphique (le code est rédigé pour vous, vous n'avez rien à changer mais assurez-vous de bien le comprendre). -->

```{r roc_compa}
# Courbe ROC pour le classifieur forêt aléatoire
plot(cardio2_rf_perf, col = "darkgreen")
# Ajout de celui à vecteurs supports
plot(cardio2_svm_perf, col = "darkred", add = TRUE)
abline(a = 0, b = 1, lty = 2)
legend("bottomright", inset = 0.1,
  legend = c("Forêt aléatoire", "Machine à vecteurs supports"), lty = 1,
  col = c("darkgreen", "darkred"))
```

# Discussion et conclusion

<!--% Indiquez ci-dessous en 3 phrases maximum quel classifieur vous considérez comme le meilleur, et pourquoi ? Est-il le meilleur quel que soit le seuil de détection retenu ? -->

...votre discussion ici...

<!--# Les combinaisons utilisées ici (train/test + courbes ROC) pour comparer deux algorithmes de classification, ou dans le document cardio_proportions.qmd (validation croisée et manipulation des propriétés/des priors) peuvent être recombinées à souhait. Il est possible d'utiliser la validation croisée partout, sauf si l'on a dupliqué les items, tout comme il est possible d'utiliser la séparation en set d'apprentissage et de test partout (avec des temps de calcul plus rapides) si le nombre d'items est suffisant. De même, les métriques issues de la matrice de confusion et les courbes ROC se complètent plus qu'elles ne sont en concurrence pour vous permettre de choisir le meilleur classifieur. Ici, pour l'exercice, les deux sont compartimentés dans deux fichiers différents, mais rien ne vous empêche de les utiliser de manière concomitante pour vos classifieurs binaires. -->

# Références
